{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the missing data\n",
    "df['reviewCreatedVersion'] = df['reviewCreatedVersion'].fillna('Unknown')\n",
    "\n",
    "# Drop the unnecessary columns\n",
    "df = df.drop(['userImage', 'sortOrder'], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1. Topic Modeling (15 pts)\n",
    "1. (15 pts) Based on the topic modeling task discussed with your instructor, please write codes to\n",
    "perform the task and try to optimize your results. In your report:\n",
    "\n",
    "    - Paste the key line of your code and the screenshot of relevant results in your report.\n",
    "    - Discuss the optimization (if any) you made to improve the model performance.\n",
    "    - Write one paragraph to discuss the main findings or takeaways from your result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from gensim.models import TfidfModel, LsiModel\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.models.callbacks import PerplexityMetric\n",
    "\n",
    "\n",
    "# Define stop words and lemmatizer\n",
    "stop_words = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Define text preprocessing function\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Tokenize text\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    # Remove stop words and words with length < 3\n",
    "    tokens = [token for token in tokens if token not in stop_words and len(token) > 2]\n",
    "    # Lemmatize tokens\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    # Join tokens back into text\n",
    "    text = ' '.join(tokens)\n",
    "    return text\n",
    "\n",
    "# Apply text preprocessing to review content\n",
    "df['content_clean'] = df['content'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic modeling using LSI from gensim\n",
    "from gensim import corpora, models, similarities\n",
    "\n",
    "# Tokenize documents\n",
    "texts = [doc.split() for doc in df['content_clean']]\n",
    "\n",
    "# Create dictionary and corpus\n",
    "dictionary = Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LSI model\n",
    "tfidf = TfidfModel(corpus)\n",
    "corpus_tfidf = tfidf[corpus]\n",
    "lsi_model = LsiModel(corpus_tfidf, id2word=dictionary, num_topics=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence score: 0.5228713037363295\n"
     ]
    }
   ],
   "source": [
    "# Get the coherence & perplexity scores for the SVD model\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models import LdaModel\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "# Calculate coherence score\n",
    "coherence_model = CoherenceModel(model=lsi_model, texts=texts, coherence='c_v')\n",
    "coherence_score = coherence_model.get_coherence()\n",
    "print(\"Coherence score:\", coherence_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of topics: 5\n",
      "Coherence score: 0.5726300919828144\n"
     ]
    }
   ],
   "source": [
    "# Optimize the number of topics using coherence score as the metric\n",
    "\n",
    "# Tokenize documents\n",
    "documents = [doc.split() for doc in df['content_clean']]\n",
    "\n",
    "# Create a dictionary from the preprocessed documents\n",
    "id2word = Dictionary(documents)\n",
    "\n",
    "# Create a corpus from the preprocessed documents\n",
    "corpus = [id2word.doc2bow(doc) for doc in documents]\n",
    "\n",
    "# Build multiple LSI models with varying numbers of topics\n",
    "min_topics = 2\n",
    "max_topics = 20\n",
    "step_size = 1\n",
    "topics_range = range(min_topics, max_topics + step_size, step_size)\n",
    "\n",
    "lsi_models = []\n",
    "for num_topics in topics_range:\n",
    "    lsi_model = LsiModel(corpus=corpus, id2word=id2word, num_topics=num_topics)\n",
    "    lsi_models.append(lsi_model)\n",
    "\n",
    "# Calculate the coherence score for each LSI model\n",
    "coherence_scores = []\n",
    "for model in lsi_models:\n",
    "    coherence_model = CoherenceModel(model=model, texts=documents, dictionary=id2word, coherence='c_v')\n",
    "    coherence_score = coherence_model.get_coherence()\n",
    "    coherence_scores.append(coherence_score)\n",
    "\n",
    "# Select the model with the highest coherence score\n",
    "optimal_model = lsi_models[coherence_scores.index(max(coherence_scores))]\n",
    "num_topics = topics_range[coherence_scores.index(max(coherence_scores))]\n",
    "\n",
    "print('Optimal number of topics:', num_topics)\n",
    "print('Coherence score:', max(coherence_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.701*\"app\" + 0.300*\"n\\'t\" + 0.232*\"task\" + 0.154*\"time\" + 0.138*\"like\"'),\n",
      " (1, '0.612*\"task\" + -0.593*\"app\" + 0.311*\"n\\'t\" + 0.158*\"day\" + 0.145*\"list\"'),\n",
      " (2,\n",
      "  '-0.725*\"n\\'t\" + 0.569*\"task\" + 0.211*\"app\" + -0.132*\"calendar\" + '\n",
      "  '-0.108*\"work\"'),\n",
      " (3,\n",
      "  '-0.444*\"n\\'t\" + 0.379*\"calendar\" + 0.364*\"time\" + -0.321*\"task\" + '\n",
      "  '0.241*\"like\"'),\n",
      " (4,\n",
      "  '-0.713*\"calendar\" + 0.367*\"time\" + -0.277*\"google\" + 0.188*\"habit\" + '\n",
      "  '-0.177*\"task\"')]\n"
     ]
    }
   ],
   "source": [
    "# Rebuild the LSI model with the optimal number of topics\n",
    "lsi_model = LsiModel(corpus=corpus, id2word=id2word, num_topics=num_topics)\n",
    "\n",
    "# Visualize the topics\n",
    "from pprint import pprint\n",
    "pprint(lsi_model.show_topics(num_words=5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
